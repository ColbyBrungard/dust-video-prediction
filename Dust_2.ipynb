{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sys\n",
    "import os\n",
    "from sklearn.externals import joblib\n",
    "print('Imported all libraries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# band = sys.argv[1] # take in argument 1 (band) if running on terminal\n",
    "band = 'Red'\n",
    "# band is one of the following \n",
    "# ['Red','Green','Blue','Red_Green','Red_Blue','Green_Blue','Red_Green_Blue']\n",
    "# ['Hue','Saturation','Value','Hue_Saturation','Hue_Value','Saturation_Value','Hue_Saturation_Value']\n",
    "number_of_bands = '1'\n",
    "# number_of_bands = sys.argv[2] # take in argument 2 (number of bands) if running on terminal\n",
    "# number_of_bands is 1,2 or 3\n",
    "print(band,type(band))\n",
    "print(number_of_bands,type(number_of_bands))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/home/josue/Codes/FFNN/Outputs/'+band+'/'\n",
    "cm_path = save_path+'confusion_matrix/'\n",
    "weight_path = save_path+'weights/'\n",
    "bias_path = save_path+'bisases/'\n",
    "validation_path = save_path+'validation/'\n",
    "miss_path = save_path+'miss/'\n",
    "summary_path = save_path+'summary/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for existing directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir1 = os.path.isdir(save_path)\n",
    "\n",
    "if dir1 == False:\n",
    "    print('Creating Saving Directory')\n",
    "    os.mkdir(save_path)\n",
    "    os.mkdir(cm_path)\n",
    "    os.mkdir(weight_path)\n",
    "    os.mkdir(bias_path)\n",
    "    os.mkdir(validation_path)\n",
    "    os.mkdir(miss_path)\n",
    "    os.mkdir(summary_path)\n",
    "    print('Created {}'.format(save_path))\n",
    "    print('Created {}'.format(cm_path))\n",
    "    print('Created {}'.format(weight_path))\n",
    "    print('Created {}'.format(bias_path))\n",
    "    print('Created {}'.format(validation_path))\n",
    "    print('Created {}'.format(miss_path))\n",
    "    print('Created {}'.format(summary_path))\n",
    "else:\n",
    "    print('Directory Already Exist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Images and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = '/scratch/josue/Data/Data_Frames/Scaled/'+band+'/' \n",
    "Training_images = joblib.load(load_path+band+'_Band_Training_Images').values\n",
    "Training_labels = joblib.load(load_path+band+'_Band_Training_Labels').values\n",
    "print(Training_images.shape)\n",
    "print(Training_labels.shape)\n",
    "\n",
    "\n",
    "Test_images = joblib.load(load_path+band+'_Band_Test_Images').values\n",
    "Test_labels = joblib.load(load_path+band+'_Band_Test_Labels').values\n",
    "print(Test_images.shape)\n",
    "print(Test_labels.shape)\n",
    "\n",
    "\n",
    "print(\"Loaded:\"+load_path+band+'_Band_Training_Images')\n",
    "print(\"Loaded:\"+load_path+band+'_Band_Training_Labels')\n",
    "print(\"Loaded:\"+load_path+band+'_Band_Test_Images')\n",
    "print(\"Loaded:\"+load_path+band+'_Band_Test_Labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get image class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_cls = np.argmax(Test_labels, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The size of the original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if number_of_bands == '1':\n",
    "    img_shape = (72,128,1)\n",
    "if number_of_bands == '2':\n",
    "    img_shape = (72,128,2)\n",
    "#     print(\"Image shape is {}\".format(img_shape))\n",
    "if number_of_bands == '3':\n",
    "    img_shape = (72,128,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten Image demensions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size_flat = img_shape[0]*img_shape[1]*img_shape[2]\n",
    "print(\"flat image length is {}\".format(img_size_flat))\n",
    "# Number of classes, one class for each category (dust,non_dust)\n",
    "num_classes = 2\n",
    "print(\"Number of classifications {}\".format(num_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, img_size_flat]) # placeholder for input data\n",
    "y_true = tf.placeholder(tf.float32, [None, num_classes]) # placeholder for input labels \n",
    "y_true_cls = tf.placeholder(tf.int64, [None]) # placeholder for true classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables to Optimize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tf.Variable(tf.zeros([img_size_flat, num_classes])) # initializes weights as zeros \n",
    "biases = tf.Variable(tf.zeros([num_classes]))  # initializes biases as zeros "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model (Multinomial Classification)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = tf.matmul(x, weights) + biases  # sets up linear model\n",
    "y_pred = tf.nn.softmax(logits) # activation function use softmax for multiple classification use sigmoid for binary\n",
    "y_pred_cls = tf.argmax(y_pred, axis=1) # argmax shows the index that has the highest output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,labels=y_true) # computes distance from logits and labels\n",
    "cost = tf.reduce_mean(cross_entropy) # reduces the cost or loss also knows as backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=alpha).minimize(cost) # uses gradient desent \n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls) # checks for correct predictions\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) # calculates accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Run TensorFlow \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session() \n",
    "session.run(tf.global_variables_initializer()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimize gets batches of images and labels then runs tensor flow session to optimeze model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(num_iterations,cnt):\n",
    "    for i in range(num_iterations):\n",
    "        batch_index = np.random.choice(len(Training_images), size=batch_size) # segment the data\n",
    "        x_batch = Training_images[batch_index] # get batch of images  \n",
    "        y_true_batch = Training_labels[batch_index] # get batch of labels \n",
    "        session.run(optimizer, feed_dict={x: x_batch, y_true: y_true_batch}) # run the optimization \n",
    "        \n",
    "        cm = Confusion_matrix(); # generate confusion matrix\n",
    "        w = session.run(weights) # generate weights\n",
    "        b = session.run(biases) # generate bias\n",
    "        \n",
    "        cm_file = cm_path+'/cm_'+'{0:0>4}'.format(cnt) # set name for confusion matrix file\n",
    "        weight_file = weight_path+'Weights_'+'{0:0>4}'.format(cnt) # set name for weights file\n",
    "        bias_file =   bias_path+'Bias_'+'{0:0>4}'.format(cnt) # set name for bias file\n",
    "        \n",
    "        np.save(cm_file, cm) # save confusion matrix\n",
    "        np.save(weight_file, w) # save weights\n",
    "        np.save(bias_file, b) # save biases\n",
    "        \n",
    "        cnt += 1\n",
    "    return w,b,cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print_accuracy runs tensor flow session and calculates accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracy():\n",
    "    # Use TensorFlow to compute the accuracy.\n",
    "    acc = session.run(accuracy, feed_dict=feed_dict_test)\n",
    "    \n",
    "    # Print the accuracy.\n",
    "    print(\"Accuracy on test-set: {0:.1%}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion_matrix runs tensor flow session and compares predicted class vs true class and generates confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Confusion_matrix():\n",
    "    # Get the true classifications for the test-set.\n",
    "    cls_true = data_test_cls\n",
    "    \n",
    "    # Get the predicted classifications for the test-set.\n",
    "    cls_pred = session.run(y_pred_cls, feed_dict=feed_dict_test)\n",
    "\n",
    "    # Get the confusion matrix using sklearn.\n",
    "    cm = confusion_matrix(y_true=cls_true,\n",
    "                          y_pred=cls_pred)\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance before any optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feed in data to placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict_test = {x: Test_images,\n",
    "                  y_true: Test_labels,\n",
    "                  y_true_cls: data_test_cls}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_accuracy() # print accuracy at intial state of model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0 # counter \n",
    "acc = 0 # initial accuracy \n",
    "batch_size = 10 # batch size\n",
    "alpha = 0.5 # learning rate\n",
    "\n",
    "while acc < .95: # break if accuracy reaches 95\n",
    "    if cnt == 500: # break if counter reaches 500 iterations\n",
    "        break\n",
    "    w,b,cm = optimize(1,cnt)  # optimeze model save weights, bias, confusion matrix\n",
    "    acc = session.run(accuracy, feed_dict=feed_dict_test) # calculate accuracy \n",
    "    cnt += 1 # increase counter by 1\n",
    "print('Number of iterations: {}'.format(cnt))\n",
    "print('Final Testing Accuracy: {}'.format(acc))\n",
    "print('Confusion matrix for testing set: {}'.format(cm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up tensorflow to validate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Validation_images = joblib.load(load_path+band+'_Band_Validation_Images').values # load validation image\n",
    "Validation_labels = joblib.load(load_path+band+'_Band_Validation_Labels').values # load validation labels\n",
    "\n",
    "print(\"Loaded:\"+load_path+band+'_Band_Validation_Images')\n",
    "print(\"Loaded:\"+load_path+band+'_Band_Validation_Labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Weights = os.listdir(weight_path) # list of all models weights \n",
    "Bias = os.listdir(bias_path) # list of all models bias \n",
    "\n",
    "Accuracy = [] # empty array for accuracy \n",
    "Recall = [] # empty array for recall \n",
    "Precision = [] # empty array for precision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Weights)): # loop through all weights\n",
    "    x_validation = tf.placeholder(tf.float32, [None, Validation_images.shape[1]]) # placeholder for new input data\n",
    "    weights = np.load(weight_path+'Weights_'+'{0:0>4}.npy'.format(i)) # load weights\n",
    "    biases = np.load(bias_path+'Bias_'+'{0:0>4}.npy'.format(i)) # load biases\n",
    "\n",
    "    logits = tf.matmul(x_validation, weights) + biases  # sets up linear model\n",
    "    y_pred = tf.nn.softmax(logits) # activation function use softmax for multiple classification use sigmoid for binary\n",
    "    y_pred_cls = tf.argmax(y_pred, axis=1) # argmax shows the index that has the highest output\n",
    "\n",
    "    session = tf.Session()  # create tensor flow session\n",
    "    session.run(tf.global_variables_initializer()) # initialize session\n",
    "    feed_dict_val = {x_validation: Validation_images} # feed in validation images\n",
    "\n",
    "    prediction = session.run(y_pred_cls, feed_dict=feed_dict_val) # run session\n",
    "    data_validation_cls = np.argmax(Validation_labels, axis=1) # classify preditions\n",
    "\n",
    "    cm = confusion_matrix(y_true=data_validation_cls,y_pred=prediction) # obtain confusion matrix\n",
    "    validation_file = validation_path+'/cm_'+'{0:0>4}'.format(i) # validation file path\n",
    "    np.save(validation_file, cm) # save confusion matrix \n",
    "\n",
    "    temp = np.reshape(cm,4).astype(float) # reshape confusion matrix\n",
    "    accuracy = (temp[0]+temp[3])/np.sum(temp) # calculate accuracy \n",
    "    recall = float((temp[-1])/(temp[-1]+temp[-2]))  # calculate recall\n",
    "    precision = float((temp[-1])/(temp[-1]+temp[-3])) # calculate precision \n",
    "    Accuracy.append(accuracy) # append accuracy \n",
    "    Recall.append(recall) # append recall\n",
    "    Precision.append(precision) # append precision\n",
    "    \n",
    "\n",
    "    for j in range(len(prediction)): # loop through all predictions \n",
    "        if prediction[j] != data_validation_cls[j]: # check if prediction matches label\n",
    "            # create text file of misclassified frames\n",
    "            with open(miss_path+'Misclassification_Index_'+'{0:0>4}'.format(i)+'.txt', 'a') as the_file:\n",
    "                the_file.write('wrong classification at index {}\\n'.format(j))\n",
    "    print('Completed Validation for {}'.format(i))\n",
    "\n",
    "np.save(summary_path+'accuracy', Accuracy) # save accuracy \n",
    "np.save(summary_path+'recall', Recall) # save recall\n",
    "np.save(summary_path+'precision', Precision) # save precision "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
